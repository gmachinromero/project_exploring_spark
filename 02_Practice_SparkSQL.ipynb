{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526818ce-ff4b-429e-9520-2989ac78249f",
   "metadata": {},
   "source": [
    "## 1. SQLContext\n",
    "\n",
    "Importar la librería de pyspark y crea una SparkSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b6136db-611e-435c-8117-ed33619bc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías y dependencias\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16489b6-9eac-419c-b1af-c2c481836295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/24 16:51:09 WARN Utils: Your hostname, gmachin resolves to a loopback address: 127.0.1.1; using 192.168.0.19 instead (on interface wlp3s0)\n",
      "22/09/24 16:51:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.2.0/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/09/24 16:51:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# SparkSession\n",
    "spark = SparkSession.builder.appName(\"walmart\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c35ff64-651e-4602-b303-049b808b7c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.19:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>walmart</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5a0cb7ac70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f493f2-feb7-4f73-a8ac-6a34ba253019",
   "metadata": {},
   "source": [
    "## 2. Cargar datos\n",
    "\n",
    "Carga los datos de Walmart (.csv) contenidos en el directorio ficheros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce0e589f-7e6e-468f-8c72-895cdf89ab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./ficheros/walmart_stock.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e0b46-172d-4e03-a78c-bb0dd66e2c5b",
   "metadata": {},
   "source": [
    "Analiza que tipo de datos son, y sus valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf27b85-380a-44ec-a2a8-b99b5c96ab78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5609c75e-b2a0-4104-9f79-73d4cd682b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|      Date|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|      1258|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean|      null| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|      null|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|2012-01-03|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|2016-12-30|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc487ca-13d5-4aa9-adf8-da76c5c5ff70",
   "metadata": {},
   "source": [
    "## 3. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0c593-f6c1-4a0d-8e64-164a341eae4e",
   "metadata": {},
   "source": [
    "Crea una nueva columna denominada HV Ratio que sea el ratio de High vs. Volume calculado por día:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f40bcb5-fcb2-40f8-9f39-50db7f8932a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|            HV Ratio|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|4.819714653321546E-6|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|6.290848613094555E-6|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|4.669412994783916E-6|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|7.367338463826307E-6|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|8.915604778943901E-6|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"HV Ratio\", df[\"High\"]/df[\"Volume\"])\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fbef7-6b57-41fd-99c2-d9eb9f58dff7",
   "metadata": {},
   "source": [
    "¿Qué día se cotizo más alto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3b1bf73-e93a-4ba7-90f0-066c87e02c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+-----+---------+-------+---------+--------------------+\n",
      "|      Date|     Open|     High|  Low|    Close| Volume|Adj Close|            HV Ratio|\n",
      "+----------+---------+---------+-----+---------+-------+---------+--------------------+\n",
      "|2015-01-13|90.800003|90.970001|88.93|89.309998|8215400|83.825448|1.107310672639189...|\n",
      "+----------+---------+---------+-----+---------+-------+---------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"High\").desc()).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "967333b6-9a82-4eed-83c8-fba355833c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+-----+---------+-------+---------+--------------------+\n",
      "|      Date|     Open|     High|  Low|    Close| Volume|Adj Close|            HV Ratio|\n",
      "+----------+---------+---------+-----+---------+-------+---------+--------------------+\n",
      "|2015-01-13|90.800003|90.970001|88.93|89.309998|8215400|83.825448|1.107310672639189...|\n",
      "+----------+---------+---------+-----+---------+-------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Registrar el DtaFrame como una vista temporal\n",
    "df.createOrReplaceTempView(\"walmart\")\n",
    "\n",
    "sql_df = spark.sql(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from walmart\n",
    "    order by High desc\n",
    "    limit 1\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "sql_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
